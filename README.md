# CDSD (Jedha) â€” Bloc 1 Â· Data Infrastructure Â· Kayak / Booking

Data Lake â†’ Data Warehouse pipeline that ranks **French destinations** using **7-day weather** + **hotel** data, with **interactive maps** (Plotly/Folium).

---

## ðŸš€ Quick demo
- ðŸ—ºï¸ **Top 5 Destinations (HTML)** â€” GitHub Pages  
  https://sonydata.github.io/cdsd-jedha-2025-b01-p01-data-infra-kayak/top5destinations.html
- ðŸ¨ **Top 20 Hotels (HTML)** â€” GitHub Pages  
  https://sonydata.github.io/cdsd-jedha-2025-b01-p01-data-infra-kayak/top20hotels-v2.html
- ðŸ““ **Colab notebook (maps only)**  
  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/107LhXhZRFf22gu39KB2NhP3dPIQyRocl?usp=sharing)

| Top 5 destinations | Top 20 hotels |
|---|---|
| ![Top 5](maps/Top5destinations.png) | ![Top 20](maps/top20hotels.png) |

---

## ðŸ“„ Project description
Goal: centralize, clean, and merge **weather** (OpenWeather) and **hotel** (Booking.com) data to produce:
- a **Top-5** of cities for the next 7 days,
- a global **Top-20** of hotels,
- **CSV outputs** for the Data Lake (S3) and a **clean SQL table** (RDS).

**Weather heuristics** used to pick â€œnice weatherâ€ cities:  
`avg_max_temp > 10Â°C`, `rain_prob â‰¤ 0.25`, `avg_clouds < 55%`, `wind < 7 m/s`.

---

## ðŸ§± Architecture
1) **Acquisition** â†’ Cities â†’ Nominatim (lat/lon) â†’ OpenWeather (daily 7-day) + Booking scraping (hotels).  
2) **Data Lake (S3)** â†’ store raw & enriched CSVs.  
3) **ETL â†’ DWH (AWS RDS)** â†’ schema/type normalization, field validation & selection, enrichment via `City_ID`, **idempotent upserts**.  
4) **Analytics / Viz** â†’ Plotly & Folium â†’ export **HTML** (GitHub Pages) + **PNG**.

---

## ðŸ”Œ Data sources
- **Geocoding:** Nominatim `/search` â†’ `lat/lon` (no API key).
- **Weather:** OpenWeather **One-Call** (7-day daily: `temp`, `pop`, `rain`, `humidity`, `clouds`, `wind`).
- **Hotels (Booking.com):** name, URL, coordinates, rating, reviews, **amenities** (Ã©quipements & services), distance from center, etc.  
  _Educational scraping only (polite headers, rate limiting)._

---

## ðŸ§¹ Key transformations (pre-DWH)
- **Hotels:** extract numeric `Rate â†’ float`, cast `Number of Reviews â†’ int`, standardize column names.  
- **Weather:** parse `dt â†’ Date`, keep relevant metrics, normalize names (`ID`, `UVI`, Title_Case_With_Underscores).  
- **Merge:** `INNER JOIN` on `City_ID` â†’ drop duplicate geo cols, rename leftovers (`Dateâ†’Weather_Date`, `Min/Maxâ†’*_Temp`), place `City_ID` first.

---

## ðŸ—‚ï¸ Folders & key files

### Folders
- [`docs/`](./docs/) â€” HTML maps published via GitHub Pages (e.g., `top5destinations.html`, `top20hotels-v2.html`).
- [`maps/`](./maps/) â€” PNG previews used in the README.
- [`files for S3/`](./files%20for%20S3/) â€” CSVs ready for the Data Lake.

### Files (repo root)
| File | What it does | Output / Notes |
|---|---|---|
| `Weather_data_API.ipynb` | Weather collection (OpenWeather) + city geocoding (Nominatim). | Produces `Weather-data-sorted-3feb25*.csv`. |
| `booking_scraping_final.py` | Booking.com scraping: hotel name/URL/coords, rating, review count, amenities, distance. | Produces `hotels_clean.csv`. |
| `SQLAlchemy.ipynb` | ETL to **RDS**: cleaning, typing, weather+hotel merge via `City_ID`, staged load + upsert. | Optional export: `hotel_weather_clean_data.csv`. |
| `S3bucket_content.png` | Evidence of S3 Data Lake contents. | Screenshot. |
| `README.md` | This document. | â€” |

---

## ðŸ“¦ Deliverables
- **Data Lake (S3):** enriched weather + hotels + `city_id` â†’ [`files for S3/`](./files%20for%20S3/)  
  ![S3](S3bucket_content.png)
- **DWH (RDS):** cleaned, merged table (see `SQLAlchemy.ipynb`; `hotel_weather_clean_data.csv`).  
- **Maps:** HTML + PNG (links at the top).

---

## ðŸ› ï¸ Stack & APIs
**Python 3.10+**, Pandas, NumPy, Requests, **Folium** / **Plotly**, SQLAlchemy,  
OpenWeather One-Call, Nominatim (OSM), AWS S3 / RDS, `.env` for secrets.

 
